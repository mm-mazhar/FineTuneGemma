{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArYWe-JSrlMA",
    "outputId": "0e78c2d4-7123-4202-b9a6-d85d75a9b037"
   },
   "outputs": [],
   "source": [
    "cwd = %pwd\n",
    "print(f'Current Working Directory: {cwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nzb2GR9Cnlo",
    "outputId": "9fc589c5-e831-4760-c8f5-e1a58d0fe53a"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMwo1VeDDDiF",
    "outputId": "a42d8fcc-8a59-41c1-fe46-7824e0d7364b"
   },
   "outputs": [],
   "source": [
    "# gpu status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqWIQHsbLIaR"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnoIDrNNLIaR"
   },
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "\n",
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets==4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.55.4\n",
    "!pip install --no-deps trl==0.22.2\n",
    "\n",
    "%%capture\n",
    "!pip install \"timm==1.0.19\"   # Only for Gemma 3N\n",
    "!pip install \"gdown==5.2.0\"\n",
    "!pip install tqdm\n",
    "\n",
    "import unsloth\n",
    "# print(unsloth.__version__)\n",
    "import torch; torch._dynamo.config.recompile_limit = 64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTfBU4Zz782a",
    "outputId": "11fcc359-6fb5-46c2-dd83-22826ce00f7e"
   },
   "outputs": [],
   "source": [
    "# --- Unsloth must be imported before transformers, trl, peft ---\n",
    "from unsloth import FastVisionModel  # or FastLanguageModel\n",
    "from unsloth import get_chat_template\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "from PIL import Image\n",
    "import requests\n",
    "import gdown\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import yaml\n",
    "from transformers import TextStreamer\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9GkX4B16u7j"
   },
   "source": [
    "Download Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwxJWXpa5yfi"
   },
   "outputs": [],
   "source": [
    "def download_and_unzip(url, extract_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Downloads and unzips a file from a URL, handling both standard links\n",
    "    and Google Drive links automatically.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the .zip file to download.\n",
    "        extract_dir (str, optional): The directory to extract the files into.\n",
    "                                     Defaults to the current directory.\n",
    "    \"\"\"\n",
    "    # Create the extraction directory if it doesn't exist\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    # Determine the filename from the URL for standard links\n",
    "    if \"drive.google.com\" not in url:\n",
    "        zip_filename = os.path.basename(url)\n",
    "    else:\n",
    "        # gdown will handle naming for Google Drive files\n",
    "        zip_filename = \"downloaded_from_gdrive.zip\"\n",
    "\n",
    "    zip_path = os.path.join(extract_dir, zip_filename)\n",
    "\n",
    "    print(f\"‚¨áÔ∏è  Starting download from: {url}\")\n",
    "\n",
    "    try:\n",
    "        # --- Download Logic ---\n",
    "        if \"drive.google.com\" in url:\n",
    "            # Use gdown for Google Drive URLs\n",
    "            gdown.download(url, zip_path, quiet=False)\n",
    "        else:\n",
    "            # Use requests for standard URLs\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "            with tqdm(\n",
    "                total=total_size, unit=\"iB\", unit_scale=True, desc=f\"Downloading {zip_filename}\"\n",
    "            ) as pbar:\n",
    "                with open(zip_path, \"wb\") as f:\n",
    "                    for data in response.iter_content(chunk_size=1024 * 4):\n",
    "                        f.write(data)\n",
    "                        pbar.update(len(data))\n",
    "\n",
    "        print(f\"\\n‚úÖ Download complete. File saved to: {zip_path}\")\n",
    "\n",
    "        # --- Unzip Logic ---\n",
    "        print(f\"\\nüì¶ Unzipping {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "            zf.extractall(path=extract_dir)\n",
    "\n",
    "        print(f\"‚úÖ Successfully extracted files to: {extract_dir}\")\n",
    "\n",
    "        # --- Cleanup ---\n",
    "        os.remove(zip_path)\n",
    "        print(f\"üóëÔ∏è  Removed temporary zip file: {zip_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVNwkoy358VW",
    "outputId": "391214af-159c-48d8-b21e-4c6dcdd6a7de"
   },
   "outputs": [],
   "source": [
    "# --- Downloading Test Set ---\n",
    "DOWNLOAD_TEST_SET = False\n",
    "if DOWNLOAD_TEST_SET:\n",
    "  extract_dir = \"/content/vizwiz_test_images\"\n",
    "  if os.path.exists(extract_dir):\n",
    "    print(f\"--- Directory '{extract_dir}' already exists. Skipping download. ---\")\n",
    "  else:\n",
    "    print(\"--- Downloading Test Set  ---\")\n",
    "    # url = \"https://vizwiz.cs.colorado.edu/VizWiz_final/images/test.zip\"\n",
    "    url = \"https://drive.google.com/uc?export=download&id=1qiZVdJo9kAVYy7OUaPjY1Dbmh5UirEB9\"\n",
    "    download_and_unzip(url=url, extract_dir=extract_dir)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1gsUftBr5UV"
   },
   "source": [
    "Setup HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NG6C5eJjr709",
    "outputId": "6b25f4e2-c27a-4a34-e2ea-8c3383c65d7a"
   },
   "outputs": [],
   "source": [
    "# Log in to Hugging Face\n",
    "\n",
    "def get_hf_token():\n",
    "    # Check if running in Google Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import userdata\n",
    "        hf_token = userdata.get(\"HF_TOKEN\")\n",
    "        print(\"Running in Colab: using userdata for HF_TOKEN.\")\n",
    "    except ImportError:\n",
    "        # Not in Colab, try to load from .env file\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        hf_token = os.getenv(\"HF_TOKEN\")\n",
    "        print(\"Not in Colab: using .env for HF_TOKEN.\")\n",
    "    if not hf_token:\n",
    "        raise RuntimeError(\"HF_TOKEN not found in Colab userdata or .env file.\")\n",
    "    return hf_token\n",
    "\n",
    "hf_token = get_hf_token()\n",
    "login(token=hf_token)\n",
    "print(f\"HF Token: {hf_token[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_uj3Sc3qDTU"
   },
   "outputs": [],
   "source": [
    "def run_inference(model_name, image_url, prompt):\n",
    "    \"\"\"\n",
    "    Loads a fine-tuned model from Hugging Face, runs inference on an image, and prints the result in JSON format.\n",
    "    Handles both URL and local file paths for images.\n",
    "    \"\"\"\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    model, processor = FastVisionModel.from_pretrained(\n",
    "        model_name=model_name,\n",
    "        load_in_4bit=True, # Use 4bit to reduce memory use and speed up inference with Unsloth.\n",
    "        dtype=None, # None for auto detection\n",
    "    )\n",
    "    print(\"Model and processor loaded successfully.\")\n",
    "\n",
    "    # Chat Template\n",
    "    processor = get_chat_template(\n",
    "    processor,\n",
    "    \"gemma-3\"\n",
    "    )\n",
    "\n",
    "    # Prepare for inference\n",
    "    FastVisionModel.for_inference(model)\n",
    "\n",
    "    try:\n",
    "        print(f\"Opening image: {image_url}\")\n",
    "        if image_url.startswith(\"http://\") or image_url.startswith(\"https://\"):\n",
    "            image = Image.open(requests.get(image_url, stream=True).raw).convert(\"RGB\")\n",
    "        elif os.path.exists(image_url):\n",
    "            image = Image.open(image_url).convert(\"RGB\")\n",
    "        else:\n",
    "            print(f\"Error: Image not found at {image_url}\")\n",
    "            return\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load image: {e}\")\n",
    "        return\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": prompt}],\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    print(\"Running inference...\")\n",
    "    # Set max_new_tokens to a reasonable value to avoid generating the prompt multiple times\n",
    "    outputs = model.generate(**inputs, max_new_tokens=300, use_cache=True, eos_token_id=processor.tokenizer.eos_token_id)\n",
    "    result = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Extract only the generated text after the assistant's turn\n",
    "    assistant_start = result.find(\"model\\n\")\n",
    "    if assistant_start != -1:\n",
    "        # Get everything after the \"model\" token\n",
    "        full_generation = result[assistant_start + len(\"model\\n\"):]\n",
    "        # Split by newline and take only the first complete line\n",
    "        generated_text = full_generation.split('\\n')[0]\n",
    "    else:\n",
    "        generated_text = \"Could not extract generated text.\"\n",
    "\n",
    "    # Prepare JSON-like output\n",
    "    output_data = {\n",
    "        \"image_source\": image_url,\n",
    "        # \"prompt\": prompt,\n",
    "        \"generated_description\": generated_text.strip() # Remove leading/trailing whitespace\n",
    "    }\n",
    "\n",
    "    # Print the result as JSON\n",
    "    print(\"\\n--- Inference Result (JSON) ---\")\n",
    "    print(json.dumps(output_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSNiN-mVTvo7"
   },
   "source": [
    "Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4qBu0EqTpKW"
   },
   "outputs": [],
   "source": [
    "# --- Define Constants ---\n",
    "MODEL_NAME = \"mazqoty/gemma-3n-vizWiz-finetuned\"\n",
    "# IMAGE_URL = \"http://images.cocodataset.org/val2017/000000039769.jpg\"  # A sample image of cats\n",
    "IMAGE_URL = \"http://images.cocodataset.org/test-stuff2017/000000000416.jpg\"\n",
    "\n",
    "# Load image from Disk/Downloaded Test Set\n",
    "# IMAGE_URL=  \"/content/vizwiz_test_images/test/VizWiz_test_00000003.jpg\"\n",
    "# IMAGE_URL = \"/content/vizwiz_test_images/test/VizWiz_test_00000052.jpg\"\n",
    "\n",
    "PROMPT = \"\"\"You are a helpful assistant for a visually impaired person. Your task is to describe the scene in the provided image clearly and concisely, focusing on potential obstacles or key objects.\"\"\"\n",
    "# PROMPT = \"Write a short, clear description of this image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "referenced_widgets": [
      "a54fdbb6a0564be298b2ff378cc4d9f7",
      "2d7fd05d815d47fc9092a00bc5e5e88f",
      "74aee5d5519a4b39b0a892eff142ffb1",
      "1dd71c5a4d91462c99fef04ac7964ce2",
      "cec3a9b8fa5f449b948b5fac2f1dcfbd",
      "5d601820ef5f4777ba43677b7e0a6e87",
      "bd11274896f74198ba1c4a13b1f76f2c",
      "1ae0fc961e454c39af8d674bff5f164f",
      "c802f0fcae3a4985bc5ff5b21a176342",
      "88f7d9394fa44ac6b9659fe46f820d76",
      "4d13172132cb4edfbdfeb06221617678"
     ]
    },
    "id": "sszqUpS3qq8s",
    "outputId": "e467a611-f94a-44cc-cb85-8133f6145275"
   },
   "outputs": [],
   "source": [
    "run_inference(MODEL_NAME, IMAGE_URL, PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3UHTPyaFpGs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
